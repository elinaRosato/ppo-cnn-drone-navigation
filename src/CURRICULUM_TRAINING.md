# Curriculum Training Guide

## Why Curriculum Learning?

Your current training tries to learn everything at once:
- âŒ Forward movement
- âŒ Goal seeking
- âŒ Altitude constraints
- âŒ Obstacle avoidance
- âŒ Camera-based vision

**That's too much!** Curriculum learning breaks it into stages.

---

## The 4-Stage Curriculum

### Stage 1: Forward Movement (50k steps, ~1 hour)
**Goal**: Learn that moving forward = good

**What it learns:**
- Move forward when commanded
- Don't move backward
- Basic drone control

**Files:**
- `train_stage1_forward.py`
- `airsim_env_stage1.py`

**Success criteria:**
- Episode length > 400 steps
- Mean reward > +300

**Command:**
```bash
python train_stage1_forward.py
```

---

### Stage 2: Goal Seeking (200k steps, ~3 hours)
**Goal**: Navigate to random goal positions

**Resumes from**: Stage 1 model

**What it learns:**
- Recognize goal direction
- Navigate toward goals
- Rotate to face goals

**Files:**
- `train_stage2_goals.py`
- `airsim_env_stage2.py`

**Success criteria:**
- Reaches goals 30%+ of time
- Mean reward > +500

**Command:**
```bash
python train_stage2_goals.py
```

---

### Stage 3: Altitude Constraints (250k steps, ~3-5 hours)
**Goal**: Navigate while respecting min/max altitude

**Resumes from**: Stage 2 model

**What it learns:**
- Navigate to goals at varying altitudes
- Respect min/max altitude bounds
- Avoid altitude violations

**Files:**
- `train_stage3_altitude.py`
- `airsim_env_stage3.py`

**Success criteria:**
- Reaches goals 40%+ of time
- Mean reward > +600
- Altitude violations < 10% of steps

**Command:**
```bash
python train_stage3_altitude.py
```

---

### Stage 4: Obstacle Avoidance (400k steps, ~4-8 hours)
**Goal**: Navigate around obstacles to reach goals

**Resumes from**: Stage 3 model

**What it learns:**
- Detect obstacles using camera
- Navigate around obstacles
- Reach goals despite obstacles

**Files:**
- `train_stage4_obstacles.py`
- `airsim_env_stage4.py`

**Success criteria:**
- Reaches goals 30%+ of time (with obstacles)
- Mean reward > +500
- Collision rate < 20% of episodes

**Important:** Use 'Blocks' environment in AirSim!

**Command:**
```bash
python train_stage4_obstacles.py
```

---

## Training Workflow

```bash
# Stage 1: Learn forward movement
python train_stage1_forward.py
# Wait for completion (~1 hour)

# Stage 2: Add goal seeking (resumes from Stage 1)
python train_stage2_goals.py
# Wait for completion (~3 hours)

# Stage 3: Add altitude constraints (resumes from Stage 2)
python train_stage3_altitude.py
# Wait for completion (~3-5 hours)

# Stage 4: Add obstacles (resumes from Stage 3)
# IMPORTANT: Switch to 'Blocks' environment in AirSim before starting!
python train_stage4_obstacles.py
# Wait for completion (~4-8 hours)
```

---

## Advantages vs. Training Everything at Once

| Approach | Time to First Success | Final Performance | Debugging |
|----------|----------------------|-------------------|-----------|
| **All at once** | Never (stuck) | Poor | Hard to debug |
| **Curriculum** | ~4 hours | Good | Easy to see what works |

---

## Monitoring Progress

### Stage 1 (Forward Movement):
```bash
tensorboard --logdir=./logs_stage1/tensorboard/
```
Watch for:
- `ep_rew_mean` > +300
- `ep_len_mean` > 400

### Stage 2 (Goal Seeking):
```bash
tensorboard --logdir=./logs_stage2/tensorboard/
```
Watch for:
- `ep_rew_mean` > +500
- Evaluation success rate > 30%

### Stage 3 (Altitude Constraints):
```bash
tensorboard --logdir=./logs_stage3/tensorboard/
```
Watch for:
- `ep_rew_mean` > +600
- Evaluation success rate > 40%
- Low altitude violation rate

### Stage 4 (Obstacle Avoidance):
```bash
tensorboard --logdir=./logs_stage4/tensorboard/
```
Watch for:
- `ep_rew_mean` > +500
- Evaluation success rate > 30%
- Collision rate decreasing

---

## When to Move to Next Stage

**Don't rush!** Each stage should:
1. Show consistent positive rewards
2. Meet the success criteria
3. Plateau (no more improvement)

**Typical timeline:**
- Stage 1: 30 min - 1 hour
- Stage 2: 2-4 hours
- Stage 3: 3-5 hours
- Stage 4: 4-8 hours

**Total**: ~10-18 hours for a fully trained agent

---

## Comparison to Original Approach

**Original (`train_ppo_v3_baby_steps.py`):**
- Trains everything simultaneously
- Gets stuck in local minimum
- 100k+ steps with no progress

**Curriculum:**
- Stage-by-stage mastery
- Each stage builds on previous
- Clear progress at each stage
- Much more likely to succeed!

---

## Next Steps

1. **Start with Stage 1**:
   ```bash
   python train_stage1_forward.py
   ```

2. **Watch TensorBoard** to see it learn forward movement

3. **When Stage 1 plateaus** (~50k steps), move to Stage 2:
   ```bash
   python train_stage2_goals.py
   ```

4. **When Stage 2 plateaus** (~200k steps), move to Stage 3:
   ```bash
   python train_stage3_altitude.py
   ```

5. **When Stage 3 plateaus** (~250k steps), switch to Blocks environment and move to Stage 4:
   ```bash
   python train_stage4_obstacles.py
   ```

6. **Deploy!** Use the final model for autonomous navigation

---

## This is Standard Practice!

Examples from research:
- **OpenAI Dota 2**: 5 curriculum stages
- **DeepMind AlphaStar**: 3 curriculum stages
- **Most robotics**: 3-4 curriculum stages

**Your instinct was 100% correct!** ðŸŽ¯
